{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78c0d97-d670-4262-9c6b-56abaf2eeb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!mkdir squad\n",
    "!wget https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_train-v1.1.json  -O squad/train-v2.0.json\n",
    "!wget https://raw.githubusercontent.com/chiahsuan156/Spoken-SQuAD/master/spoken_test-v1.1_WER54.json -O squad/dev-v2.0.json\n",
    "!pip install transformers evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496c8e61-278b-487a-99b4-cd4fb2632353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
    "import time\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e90fe8-353c-4db4-8af8-90d42b51d303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Examples: 37111 Validation Examples: 17841\n",
      "Sample Random Train Example:\n",
      "Text: the slowing sales growth has been attributed to the maturing pc market which constituted sixty six percent of del sales and analysts suggested that del needed to make inroads into nine p c business this segment such as storage services and servers. dells price advantage was tied to its ultra lean manufacturing for desktop p cs but this became less important as savings became harder to find inside the company supply chain and as competitors such as hewlett packard and these are made their p c manufacturing operations more efficient to match down weakening dells traditional price differentiation. throughout the entire pc industry declines in prices along with commensurate increases in performance meant that dell had fewer opportunities to accel to their customers lucrative strategy of encouraging buyers to upgrade the processor memory. as a result the company was selling a greater proportion of inexpensive p c span the fuller which eroded profit margins. the laptop segment had become the fastest growing of the pc market but dont produce low cost notebooks in china like other pc manufacturers which eliminated dells manufacturing cost advantages plus bells reliance on internet sales meant that it missed out on growing notebooks theyll sing bait box stores. c n n has suggested that dealt with getting trapped in the increasing commodities station of high volume low margin computers which prevented it from offering more exciting devices that consumers demanded.\n",
      "Query: What market made up the majority of Dell's sales?\n",
      "Answer: {'answer_start': 61, 'text': 'pc'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Load data from JSON files\n",
    "def load_squad_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    texts, queries, answers = [], [], []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                # Check if the question is answerable (use default False if 'is_impossible' is not present)\n",
    "                if qa.get('is_impossible', False):\n",
    "                    continue  # Skip unanswerable questions for simplicity\n",
    "                for answer in qa['answers']:\n",
    "                    texts.append(context)\n",
    "                    queries.append(question)\n",
    "                    answers.append({\n",
    "                        'answer_start': answer['answer_start'],\n",
    "                        'text': answer['text']\n",
    "                    })\n",
    "    return texts, queries, answers\n",
    "\n",
    "# Specify the paths for the SQuAD data files\n",
    "train_path = Path('squad/train-v2.0.json')\n",
    "val_path = Path('squad/dev-v2.0.json')\n",
    "\n",
    "# Load train and validation data\n",
    "train_texts, train_queries, train_answers = load_squad_data(train_path)\n",
    "val_texts, val_queries, val_answers = load_squad_data(val_path)\n",
    "\n",
    "# Display a random example from the training data\n",
    "random_index = random.randint(0, len(train_texts) - 1)\n",
    "print(\"Train Examples:\", len(train_texts), \"Validation Examples:\", len(val_texts))\n",
    "print(\"Sample Random Train Example:\")\n",
    "print(\"Text:\", train_texts[random_index])\n",
    "print(\"Query:\", train_queries[random_index])\n",
    "print(\"Answer:\", train_answers[random_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8589e151-b3ff-4017-9817-d295938b671a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure each answer has an 'answer_end'\n",
    "def set_end_positions(answers):\n",
    "    for answer in answers:\n",
    "        start_idx = answer['answer_start']\n",
    "        answer['answer_end'] = start_idx + len(answer['text'])\n",
    "\n",
    "set_end_positions(train_answers)\n",
    "set_end_positions(val_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36006a76-67ff-4546-b622-ab512dc50526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "model_name = \"distilbert-base-uncased\"  # or another suitable QA model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Now tokenize each example with `encode_plus`\n",
    "train_encodings = {\n",
    "    'input_ids': [],\n",
    "    'attention_mask': [],\n",
    "    'start_positions': [],\n",
    "    'end_positions': []\n",
    "}\n",
    "\n",
    "for text, query in zip(train_texts, train_queries):\n",
    "    encodings = tokenizer.encode_plus(\n",
    "        text,\n",
    "        query,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        return_tensors=\"pt\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    train_encodings['input_ids'].append(encodings['input_ids'])\n",
    "    train_encodings['attention_mask'].append(encodings['attention_mask'])\n",
    "\n",
    "# Similar approach for validation data\n",
    "val_encodings = {\n",
    "    'input_ids': [],\n",
    "    'attention_mask': []\n",
    "}\n",
    "\n",
    "for text, query in zip(val_texts, val_queries):\n",
    "    encodings = tokenizer.encode_plus(\n",
    "        text,\n",
    "        query,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        return_tensors=\"pt\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    val_encodings['input_ids'].append(encodings['input_ids'])\n",
    "    val_encodings['attention_mask'].append(encodings['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d7bd51-fd9e-4d70-9421-f2a9b6b374d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adjust the function to add start and end positions for each encoding\n",
    "def add_token_positions(texts, queries, answers):\n",
    "    encodings = {\n",
    "        'input_ids': [],\n",
    "        'attention_mask': [],\n",
    "        'start_positions': [],\n",
    "        'end_positions': []\n",
    "    }\n",
    "\n",
    "    for text, query, answer in zip(texts, queries, answers):\n",
    "        # Encode text and query with overflow and stride\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            query,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True,\n",
    "            return_overflowing_tokens=True\n",
    "        )\n",
    "\n",
    "        # Find start and end positions within each encoding\n",
    "        offset_mapping = encoding['offset_mapping'][0]\n",
    "        start_char = answer['answer_start']\n",
    "        end_char = answer['answer_end']\n",
    "        \n",
    "        # Initialize start and end token positions as None\n",
    "        start_token = None\n",
    "        end_token = None\n",
    "\n",
    "        # Loop through offset mapping to find the token positions\n",
    "        for idx, (start, end) in enumerate(offset_mapping):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "                break\n",
    "\n",
    "        # Handle cases where token positions are not found\n",
    "        if start_token is None:\n",
    "            start_token = tokenizer.model_max_length\n",
    "        if end_token is None:\n",
    "            end_token = tokenizer.model_max_length\n",
    "\n",
    "        # Append the results for each instance\n",
    "        encodings['input_ids'].append(encoding['input_ids'][0])\n",
    "        encodings['attention_mask'].append(encoding['attention_mask'][0])\n",
    "        encodings['start_positions'].append(start_token)\n",
    "        encodings['end_positions'].append(end_token)\n",
    "\n",
    "    # Convert lists to tensors for compatibility\n",
    "    encodings['input_ids'] = torch.stack(encodings['input_ids'])\n",
    "    encodings['attention_mask'] = torch.stack(encodings['attention_mask'])\n",
    "    encodings['start_positions'] = torch.tensor(encodings['start_positions'])\n",
    "    encodings['end_positions'] = torch.tensor(encodings['end_positions'])\n",
    "\n",
    "    return encodings\n",
    "\n",
    "# Apply the function to create encodings with token positions\n",
    "train_encodings = add_token_positions(train_texts, train_queries, train_answers)\n",
    "val_encodings = add_token_positions(val_texts, val_queries, val_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0e31c7-7d59-4a7e-9e8f-2ce4c9151ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a32691c-0364-4085-9c20-cc062551aa2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb13d24-a68e-475e-aecb-f4c39f486b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab5314e-e15b-4ad5-84c0-2147b570be6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.997101/ipykernel_107335/2853054750.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000/2320, Loss: 1.6515426635742188\n",
      "Step 2000/2320, Loss: 1.1297216415405273\n",
      "Epoch 1/5\n",
      "Training Loss: 2.1570609541288737, Validation Loss: nan\n",
      "Step 1000/2320, Loss: 1.6353263854980469\n",
      "Step 2000/2320, Loss: 1.3644336462020874\n",
      "Epoch 2/5\n",
      "Training Loss: 1.3003990753329007, Validation Loss: nan\n",
      "Step 1000/2320, Loss: 1.0834035873413086\n",
      "Step 2000/2320, Loss: 0.533228874206543\n",
      "Epoch 3/5\n",
      "Training Loss: 0.9302236610124337, Validation Loss: nan\n",
      "Step 1000/2320, Loss: 0.5495268106460571\n",
      "Step 2000/2320, Loss: 0.703312337398529\n",
      "Epoch 4/5\n",
      "Training Loss: 0.6554086196204197, Validation Loss: nan\n",
      "Step 1000/2320, Loss: 1.362839937210083\n",
      "Step 2000/2320, Loss: 0.45770543813705444\n",
      "Epoch 5/5\n",
      "Training Loss: 0.4811129829782093, Validation Loss: nan\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.amp import autocast, GradScaler  # Updated import for amp\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "print_every = 1000\n",
    "scaler = GradScaler(\"cuda\")  # Updated GradScaler usage\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Training Loop\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use mixed precision with autocast\n",
    "        with autocast(\"cuda\"):  # Updated autocast usage\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Scale loss for mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Print loss every `print_every` steps\n",
    "        if (step + 1) % print_every == 0:\n",
    "            print(f\"Step {step + 1}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation (Evaluated every epoch in this case, can be adjusted)\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "            # Collect token indices instead of decoding to text for each step\n",
    "            for i in range(len(input_ids)):\n",
    "                start_idx = torch.argmax(start_logits[i])\n",
    "                end_idx = torch.argmax(end_logits[i]) + 1\n",
    "                val_preds.append((input_ids[i][start_idx:end_idx]).tolist())\n",
    "                val_labels.append((input_ids[i][batch['start_positions'][i]:batch['end_positions'][i] + 1]).tolist())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Print training and validation loss\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45dfcc03-2abb-484d-a25d-4f1a7ce88f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_f1(pred, true):\n",
    "    pred_tokens = pred.split()\n",
    "    true_tokens = true.split()\n",
    "    common = set(pred_tokens) & set(true_tokens)\n",
    "    \n",
    "    if len(common) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(true_tokens)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9e39ae-f6c1-4c44-b388-a7099fdb201e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_f1(predictions, labels):\n",
    "    def f1_score(pred, label):\n",
    "        pred_tokens = Counter(pred.split())\n",
    "        label_tokens = Counter(label.split())\n",
    "        \n",
    "        # Find common tokens between prediction and label\n",
    "        common_tokens = pred_tokens & label_tokens\n",
    "        num_common = sum(common_tokens.values())\n",
    "        \n",
    "        if num_common == 0:\n",
    "            return 0.0\n",
    "\n",
    "        precision = num_common / sum(pred_tokens.values())\n",
    "        recall = num_common / sum(label_tokens.values())\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    # Calculate F1 for each prediction-label pair and average them\n",
    "    f1_scores = [f1_score(pred, label) for pred, label in zip(predictions, labels)]\n",
    "    return sum(f1_scores) / len(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a7293a-7d92-41f7-ba1f-0ae745f7c2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, tokenizer, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            # Forward pass to get logits\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "            # Find the best start and end positions for the answer\n",
    "            for i in range(len(input_ids)):\n",
    "                start_idx = torch.argmax(start_logits[i])\n",
    "                end_idx = torch.argmax(end_logits[i]) + 1\n",
    "\n",
    "                # Decode predicted answer and true answer\n",
    "                pred_text = tokenizer.decode(input_ids[i][start_idx:end_idx], skip_special_tokens=True)\n",
    "                true_text = tokenizer.decode(input_ids[i][start_positions[i]:end_positions[i] + 1], skip_special_tokens=True)\n",
    "\n",
    "                predictions.append(pred_text)\n",
    "                labels.append(true_text)\n",
    "\n",
    "    return predictions, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8da988d3-61bc-4c14-bbb6-cae9950dd48c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.997101/ipykernel_107335/2853054750.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.13961467801300054\n"
     ]
    }
   ],
   "source": [
    "# Assuming `val_loader` is your validation DataLoader and `device` is set to \"cuda\" or \"cpu\"\n",
    "predictions, labels = get_predictions(model, tokenizer, val_loader, device)\n",
    "f1 = compute_f1(predictions, labels)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36bd1614-7b0f-4ebb-a7ba-b64c23029189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    if len(scores_for_ground_truths)==0: return 0\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "def evaluate(gold_answers, predictions):\n",
    "    f1 = exact_match = total = 0\n",
    "\n",
    "    for ground_truths, prediction in zip(gold_answers, predictions):\n",
    "        total += 1\n",
    "        exact_match += metric_max_over_ground_truths(\n",
    "                    exact_match_score, prediction, ground_truths)\n",
    "        f1 += metric_max_over_ground_truths(\n",
    "          f1_score, prediction, [ground_truths])\n",
    "    \n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "\n",
    "    return {'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec489856-80ed-4223-b0b1-bef1cee79ee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'references' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(references,answers)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'references' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate(references,answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d471e-f7db-44c1-aa18-5d6b9154dcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
